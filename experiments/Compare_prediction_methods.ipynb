{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "npg0ldu2c2act9e02hcxd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 01:30:08.042677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#################################           Load libs                      #############################################\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import yfinance as yf\n",
    "from ts_rnn.model import TS_RNN\n",
    "from keras_tuner import HyperParameters\n",
    "from ts_rnn.utils import metrics_eval, train_val_test_pred_plot\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('CRITICAL')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer, LogTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xzgjyu3x0uldxh26ceiyko",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "0rfy16dsnwl8nz5m9bwfqx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'There will be 2400 fits'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Config\n",
    "hp = HyperParameters()\n",
    "rnn_arch = {\"layers\": [\n",
    "                        [\"LSTM\", {\"units\": hp.Int(name='units',\n",
    "                                                 min_value=2,\n",
    "                                                 max_value=30,\n",
    "                                                 step=10,\n",
    "                                                 default=12\n",
    "                                                ),\n",
    "                                  \"return_sequences\": False,\n",
    "                                  \"kernel_initializer\": \"glorot_uniform\",\n",
    "                                  \"activation\": hp.Choice(name='LSTM_1_activation',\n",
    "                                                          values=['relu', 'tanh', 'sigmoid', \"linear\"],\n",
    "                                                          default='relu'),\n",
    "                                  }],\n",
    "                        [\"Dropout\", {\"rate\": hp.Float(name='dropout',\n",
    "                                                      min_value=0.0,\n",
    "                                                      max_value=0.5,\n",
    "                                                      default=0.2,\n",
    "                                                      step=0.05)\n",
    "                                     }],\n",
    "                        [\"Dense\", {\"activation\": \"linear\"}]\n",
    "                    ]}\n",
    "\n",
    "my_callbacks = [callbacks.EarlyStopping(patience=10, monitor='val_loss')]\n",
    "\n",
    "CONFIG = {\n",
    "    \"TARGET\": {'TICKERS': [\n",
    "                           'YNDX.ME',\n",
    "                           'SBER.ME',\n",
    "                           'POLY.ME',\n",
    "                           'SIBN.ME',\n",
    "                           'AMZN',\n",
    "                           'AAPL',\n",
    "                           'GOOGL',\n",
    "                           'NFLX'\n",
    "                           ],\n",
    "               'MIN_DATE': '2012-01-01',\n",
    "               'MAX_DATE': '2022-01-01'},\n",
    "    \"VAL_LEN\": 7,\n",
    "    \"TEST_LEN\": 7,\n",
    "    \"CV_FOLDS\": 5,\n",
    "    \"STRATEGIES\": [\n",
    "                    \"Recursive\",\n",
    "                    \"MiMo\",\n",
    "                    \"Direct\",\n",
    "                    'DirRec',\n",
    "                    \"DirMo\"\n",
    "                ], # \"Recursive\", \"MiMo\", \"Direct\", 'DirRec', \"DirMo\"\n",
    "    \"MODEL\": {'INIT':{\n",
    "                    'rnn_arch': rnn_arch,\n",
    "                    'tuner_hp': hp,\n",
    "                    \"n_lags\": 30,\n",
    "                    \"horizon\": 7,\n",
    "                    \"tuner\": \"BayesianOptimization\", # \"RandomSearch\", \"BayesianOptimization\", \"Hyperband\"\n",
    "                    \"max_trials\": 5,\n",
    "                    \"loss\": 'mae',\n",
    "                    \"optimizer\": 'adam'\n",
    "                    },\n",
    "                'FIT':{\"epochs\": 40,\n",
    "                      \"batch_size\": 14,\n",
    "                       'callbacks': my_callbacks}\n",
    "              },\n",
    "    \"OUTLAYER_TRANSFORMERS\": 'HampelFilter',\n",
    "    \"BASE_TRANSFORMERS\": 'Differencer', # 'Differencer', 'LogTransformer', 'BoxCoxTransformer',\n",
    "    \"SEASON_TRANSFORMERS\": None,\n",
    "    \"NORM_TRANSPORMERS\": \"MinMaxScaler\",\n",
    "    \"TRANSFORMERS_ARGS\": { 'HampelFilter':{'window_length': 10},\n",
    "                                'MinMaxScaler': {\"feature_range\": (0, 1)},\n",
    "                                'Differencer': {'lags': [1]},\n",
    "                                'LogTransformer':{},\n",
    "                                'BoxCoxTransformer': {},\n",
    "                                'Deseasonalizer':{'sp': 364,\n",
    "                                                  'model': 'multiplicative'},\n",
    "                                }\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, n_splits=CONFIG[\"CV_FOLDS\"], test_size=CONFIG[\"VAL_LEN\"] +CONFIG[\"TEST_LEN\"])\n",
    "n_fits = CONFIG['MODEL']['INIT']['max_trials']  * CONFIG['CV_FOLDS'] * len(CONFIG['TARGET']['TICKERS']) * (len(CONFIG[\"STRATEGIES\"]) + CONFIG[\"VAL_LEN\"])\n",
    "f\"There will be {n_fits} fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9b70246l3puuj5wxs5u87f"
   },
   "source": [
    "## RNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "1wqnspzdtt4r15rwugkqf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seve_fig_from_array(array, path, fig_name):\n",
    "    plt.plot(array)\n",
    "    plt.savefig(os.path.join(path, fig_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "6e5q7eo80m4m9zbd9dsp3k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 21s]\n",
      "val_loss: 0.0623948760330677\n",
      "\n",
      "Best val_loss So Far: 0.0623948760330677\n",
      "Total elapsed time: 00h 00m 21s\n",
      "1/1 [==============================] - 1s 842ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "# Import targets\n",
    "targets_df = yf.download(CONFIG['TARGET']['TICKERS'],\n",
    "                         start=CONFIG['TARGET']['MIN_DATE'],\n",
    "                         end=CONFIG['TARGET']['MAX_DATE']\n",
    "                        )['Adj Close']\n",
    "if isinstance(targets_df, pd.Series):\n",
    "    targets_df.name = CONFIG['TARGET']['TICKERS'][0]\n",
    "    targets_df = targets_df.to_frame()\n",
    "full_ind = pd.date_range(targets_df.index.min(), targets_df.index.max())\n",
    "targets_df = targets_df.reindex(full_ind, fill_value=np.nan).interpolate()\n",
    "\n",
    "# Make new experiment folder\n",
    "if \"reports\" not in os.listdir('.'):\n",
    "    os.makedirs(\"./reports\")\n",
    "new_folder_num = str(len(os.listdir(\"./reports\")) + 1)\n",
    "exp_folder = os.path.join(\"./reports\", \"strategy_experiment_\" + new_folder_num)\n",
    "os.mkdir(exp_folder)\n",
    "print(f\"Save experiment in {exp_folder}\")\n",
    "\n",
    "# Save config\n",
    "CONFIG_ = deepcopy(CONFIG)\n",
    "del CONFIG_['MODEL']['INIT']['tuner_hp']\n",
    "del CONFIG_['MODEL']['FIT']['callbacks']\n",
    "with open(os.path.join(exp_folder, \"exp_config.json\"), \"w\") as outfile:\n",
    "    json.dump(CONFIG_, outfile, skipkeys=True)\n",
    "\n",
    "models_dict = {}\n",
    "\n",
    "for strategy in CONFIG[\"STRATEGIES\"]:\n",
    "    CONFIG['MODEL']['INIT']['strategy'] = strategy\n",
    "    # Create model_folder\n",
    "    model_name =  strategy\n",
    "    print(f\"Model {model_name}\")\n",
    "    model_folder = os.path.join(exp_folder, model_name)\n",
    "    if model_name not in os.listdir(exp_folder):\n",
    "        os.mkdir(model_folder)\n",
    "\n",
    "    for ticker_name in CONFIG['TARGET']['TICKERS']:\n",
    "        target = targets_df[ticker_name].dropna()\n",
    "        series_folder = os.path.join(model_folder, ticker_name.split('.')[0])\n",
    "        os.mkdir(series_folder)\n",
    "\n",
    "        cv_val_metrics, cv_test_metrics = [], []\n",
    "        cv_val_predictions, cv_test_predictions = [], []\n",
    "\n",
    "        for train_index, val_index in tscv.split(target):\n",
    "            # divide val to val and test\n",
    "            test_index = val_index[CONFIG[\"VAL_LEN\"]:]\n",
    "            val_index = val_index[:CONFIG[\"VAL_LEN\"]]\n",
    "\n",
    "            iter_folder = f\"TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}\"\n",
    "            print(iter_folder)\n",
    "\n",
    "            # Create folder for cv iteration\n",
    "            iter_folder = os.path.join(series_folder, iter_folder)\n",
    "            plots_folder = os.path.join(iter_folder, 'plots')\n",
    "            os.mkdir(iter_folder)\n",
    "            os.mkdir(plots_folder)\n",
    "            plot_id = 0\n",
    "\n",
    "            target_train, target_val, target_test = target[train_index], target[val_index], target[test_index]\n",
    "            seve_fig_from_array(target_train, plots_folder, f'{plot_id}_target')\n",
    "            plot_id+=1\n",
    "            if CONFIG[\"OUTLAYER_TRANSFORMERS\"] is not None:\n",
    "                outlayer_transformer = eval(CONFIG[\"OUTLAYER_TRANSFORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"OUTLAYER_TRANSFORMERS\"]])\n",
    "                target_train_tr = outlayer_transformer.fit_transform(target_train).interpolate(limit_direction=\"both\")\n",
    "                target_val_tr = target_val\n",
    "                seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_outlayers_removed')\n",
    "                plot_id+=1\n",
    "            else:\n",
    "                target_train_tr = target_train\n",
    "                target_val_tr = target_val\n",
    "\n",
    "            if CONFIG[\"SEASON_TRANSFORMERS\"] is not None:\n",
    "                seasonal_transformer = eval(CONFIG[\"SEASON_TRANSFORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"SEASON_TRANSFORMERS\"]])\n",
    "                target_train_tr = seasonal_transformer.fit_transform(target_train_tr)\n",
    "                target_val_tr = seasonal_transformer.transform(target_val_tr)\n",
    "                seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_{CONFIG[\"SEASON_TRANSFORMERS\"]}')\n",
    "                plot_id+=1\n",
    "\n",
    "            if CONFIG[\"BASE_TRANSFORMERS\"] is not None:\n",
    "                base_transformer = eval(CONFIG[\"BASE_TRANSFORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"BASE_TRANSFORMERS\"]])\n",
    "                target_train_tr = base_transformer.fit_transform(target_train_tr).interpolate(limit_direction=\"both\")\n",
    "                target_val_tr = base_transformer.transform(target_val_tr).interpolate(limit_direction=\"both\")\n",
    "                seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_{CONFIG[\"BASE_TRANSFORMERS\"]}')\n",
    "                plot_id+=1\n",
    "\n",
    "            # Normalize target\n",
    "            if CONFIG[\"NORM_TRANSPORMERS\"] is not None:\n",
    "                target_scaler = eval(CONFIG[\"NORM_TRANSPORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"NORM_TRANSPORMERS\"]])\n",
    "                target_train_tr = target_scaler.fit_transform(target_train_tr.values.reshape(-1, 1))\n",
    "                target_val_tr = target_scaler.transform(target_val_tr.values.reshape(-1, 1))\n",
    "\n",
    "                target_train_tr = pd.Series(target_train_tr.flatten(), index=target_train.index, name=ticker_name)\n",
    "                target_val_tr = pd.Series(target_val_tr.flatten(), index=target_val.index, name=ticker_name)\n",
    "\n",
    "                seve_fig_from_array(pd.Series(target_train_tr, index=target_train.index), plots_folder, f'{plot_id}_target_scaled')\n",
    "                plot_id+=1\n",
    "            else:\n",
    "                target_train_tr = target_train_tr\n",
    "                target_val_tr = target_val_tr\n",
    "\n",
    "            if strategy == 'DirMo':\n",
    "                CONFIG[\"MODEL\"]['INIT']['n_step_out'] = 3\n",
    "            else:\n",
    "                CONFIG[\"MODEL\"]['INIT']['n_step_out'] = 1\n",
    "\n",
    "            model = TS_RNN(save_dir=iter_folder, **CONFIG[\"MODEL\"]['INIT'])\n",
    "            model.logger.info(f'[Experiment] {model_name}')\n",
    "            model.logger.info(f'[Experiment] {ticker_name}_TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}')\n",
    "\n",
    "\n",
    "            model.fit(target_train=target_train_tr,\n",
    "                      target_val=target_val_tr,\n",
    "                      **CONFIG[\"MODEL\"]['FIT'],\n",
    "                      verbose=1)\n",
    "            \n",
    "            # Удаляем логи тюнера\n",
    "            shutil.rmtree(os.path.join(iter_folder, 'TS_RNN_tuner_log'))\n",
    "\n",
    "            predicted_val = model.predict(target=target_train_tr.iloc[-model.n_lags:],\n",
    "                                              prediction_len=CONFIG[\"VAL_LEN\"])\n",
    "            predicted_test = model.predict(target=pd.concat([target_train_tr, target_val_tr], axis=0).iloc[-model.n_lags:],\n",
    "                                              prediction_len=CONFIG[\"VAL_LEN\"])\n",
    "\n",
    "            # inverse transform\n",
    "            if CONFIG[\"NORM_TRANSPORMERS\"] is not None:\n",
    "                predicted_val = pd.Series(target_scaler.inverse_transform(predicted_val.reshape(-1, 1))\n",
    "                                                          .flatten(),\n",
    "                                             index=target_val.index)\n",
    "                predicted_test = pd.Series(target_scaler.inverse_transform(predicted_test.reshape(-1, 1))\n",
    "                                                          .flatten(),\n",
    "                                             index=target_test.index)\n",
    "            else:\n",
    "                predicted_val = pd.Series(predicted_val, index=target_val.index)\n",
    "                predicted_test = pd.Series(predicted_test, index=target_test.index)\n",
    "\n",
    "            if CONFIG[\"BASE_TRANSFORMERS\"] is not None:\n",
    "                predicted_val = base_transformer.inverse_transform(predicted_val)\n",
    "                if CONFIG[\"BASE_TRANSFORMERS\"] == 'Differencer':\n",
    "                    predicted_test = target_val[-1] + predicted_test.cumsum()\n",
    "                else:\n",
    "                    predicted_test = base_transformer.inverse_transform(predicted_test)\n",
    "\n",
    "            if CONFIG[\"SEASON_TRANSFORMERS\"] is not None:\n",
    "                predicted_val = seasonal_transformer.inverse_transform(predicted_val)\n",
    "                predicted_test = seasonal_transformer.inverse_transform(predicted_test)\n",
    "\n",
    "            predicted_val.name = ticker_name\n",
    "            predicted_val.to_csv(os.path.join(iter_folder, f'val_predictions.csv'), mode='w', sep=';')\n",
    "            predicted_test.name = ticker_name\n",
    "            predicted_test.to_csv(os.path.join(iter_folder, f'test_predictions.csv'), mode='w', sep=';')\n",
    "            \n",
    "            \n",
    "            # Calculate metrics\n",
    "            val_mertics = metrics_eval(target_val[:len(predicted_val)], predicted_val, save_dir=iter_folder, print_result=False, name=\"val_mertics\")\n",
    "            test_mertics = metrics_eval(target_test[:len(predicted_val)], predicted_test, save_dir=iter_folder, print_result=False, name='test_mertics')\n",
    "\n",
    "            cv_val_metrics.append(val_mertics)\n",
    "            cv_test_metrics.append(test_mertics)\n",
    "\n",
    "            cv_val_predictions.append(predicted_val)\n",
    "            cv_test_predictions.append(predicted_test)\n",
    "\n",
    "            train_val_test_pred_plot(train=target_train,\n",
    "                                     val=target_val,\n",
    "                                     test=target_test,\n",
    "                                     val_pred=predicted_val,\n",
    "                                     test_pred=predicted_test,\n",
    "                                     save_dir=plots_folder, show=False)\n",
    "\n",
    "        models_dict[model_name] = {} if model_name not in models_dict else models_dict[model_name]\n",
    "        models_dict[model_name][\"mean_val_metrics\"] = {} if \"mean_val_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_val_metrics\"]\n",
    "        models_dict[model_name][\"mean_test_metrics\"] = {} if \"mean_test_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_test_metrics\"]\n",
    "        models_dict[model_name][\"mean_val_metrics\"][ticker_name] = dict(pd.DataFrame(cv_val_metrics).mean())\n",
    "        models_dict[model_name][\"mean_test_metrics\"][ticker_name] = dict(pd.DataFrame(cv_test_metrics).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4c3kpkwbdps652zp3fvcs5"
   },
   "source": [
    "## Arima training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iv08goe8norwahcw0srd2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "# Create model_folder\n",
    "model_name =  \"Auto ARIMA\"\n",
    "model_folder = os.path.join(exp_folder, model_name)\n",
    "os.mkdir(model_folder)\n",
    "\n",
    "for ticker_name in CONFIG['TARGET']['TICKERS']:\n",
    "    target = targets_df[ticker_name].dropna()\n",
    "    series_folder = os.path.join(model_folder, ticker_name.split('.')[0])\n",
    "    os.mkdir(series_folder)\n",
    "\n",
    "    cv_val_metrics, cv_test_metrics = [], []\n",
    "    cv_val_predictions, cv_test_predictions = [], []\n",
    "\n",
    "    for train_index, val_index in tscv.split(target):\n",
    "        # divide val to val and test\n",
    "        test_index = val_index[CONFIG[\"VAL_LEN\"]:]\n",
    "        val_index = val_index[:CONFIG[\"VAL_LEN\"]]\n",
    "        iter_folder = f\"TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}\"\n",
    "        print(iter_folder)\n",
    "\n",
    "        # Create folder for cv iteration\n",
    "        iter_folder = os.path.join(series_folder, iter_folder)\n",
    "        plots_folder = os.path.join(iter_folder, 'plots')\n",
    "        os.mkdir(iter_folder)\n",
    "        os.mkdir(plots_folder)\n",
    "        plot_id = 0\n",
    "\n",
    "        target_train, target_val, target_test = target[train_index], target[val_index], target[test_index]\n",
    "        seve_fig_from_array(target_train, plots_folder, f'{plot_id}_target')\n",
    "        plot_id+=1\n",
    "\n",
    "        arima_model = pm.auto_arima(target_train,\n",
    "                                   start_p=1, start_q=1,\n",
    "                                   test='adf',\n",
    "                                   max_p=3, max_q=3, m=12,\n",
    "                                   start_P=0, seasonal=True,\n",
    "                                   d=None, D=1, trace=True,\n",
    "                                   error_action='ignore',\n",
    "                                   suppress_warnings=True,\n",
    "                                   stepwise=True)\n",
    "        predicted_arima = arima_model.predict(n_periods=CONFIG[\"TEST_LEN\"] * 2)\n",
    "        predicted_val = predicted_arima[:CONFIG[\"TEST_LEN\"]]\n",
    "        predicted_test = predicted_arima[CONFIG[\"TEST_LEN\"]:]\n",
    "\n",
    "        predicted_val = pd.Series(predicted_val, index=target_val.index)\n",
    "        predicted_test = pd.Series(predicted_test, index=target_test.index)\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_mertics = metrics_eval(target_val[:len(predicted_val)], predicted_val, save_dir=iter_folder, print_result=False, name=\"val_mertics\")\n",
    "        test_mertics = metrics_eval(target_test[:len(predicted_val)], predicted_test, save_dir=iter_folder, print_result=False, name='test_mertics')\n",
    "\n",
    "        cv_val_metrics.append(val_mertics)\n",
    "        cv_test_metrics.append(test_mertics)\n",
    "\n",
    "        cv_val_predictions.append(predicted_val)\n",
    "        cv_test_predictions.append(predicted_test)\n",
    "\n",
    "        train_val_test_pred_plot(train=target_train,\n",
    "                                 val=target_val,\n",
    "                                 test=target_test,\n",
    "                                 val_pred=predicted_val,\n",
    "                                 test_pred=predicted_test,\n",
    "                                 save_dir=plots_folder, show=False)\n",
    "    models_dict[model_name] = {} if model_name not in models_dict else models_dict[model_name]\n",
    "    models_dict[model_name][\"mean_val_metrics\"] = {} if \"mean_val_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_val_metrics\"]\n",
    "    models_dict[model_name][\"mean_test_metrics\"] = {} if \"mean_test_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_test_metrics\"]\n",
    "    models_dict[model_name][\"mean_val_metrics\"][ticker_name] = dict(pd.DataFrame(cv_val_metrics).mean())\n",
    "    models_dict[model_name][\"mean_test_metrics\"][ticker_name] = dict(pd.DataFrame(cv_test_metrics).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cellId": "5txv4uk4n5rre184hzow",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DirMo</th>\n",
       "      <td>32.28</td>\n",
       "      <td>3501.02</td>\n",
       "      <td>1.82</td>\n",
       "      <td>38.21</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct</th>\n",
       "      <td>32.82</td>\n",
       "      <td>3685.85</td>\n",
       "      <td>1.84</td>\n",
       "      <td>38.94</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirRec</th>\n",
       "      <td>34.11</td>\n",
       "      <td>3933.93</td>\n",
       "      <td>1.93</td>\n",
       "      <td>40.81</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive</th>\n",
       "      <td>35.56</td>\n",
       "      <td>4415.34</td>\n",
       "      <td>1.96</td>\n",
       "      <td>42.80</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiMo</th>\n",
       "      <td>37.75</td>\n",
       "      <td>6353.49</td>\n",
       "      <td>1.96</td>\n",
       "      <td>44.53</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean Absolute Error  Mean Squared Error  \\\n",
       "DirMo                    32.28             3501.02   \n",
       "Direct                   32.82             3685.85   \n",
       "DirRec                   34.11             3933.93   \n",
       "Recursive                35.56             4415.34   \n",
       "MiMo                     37.75             6353.49   \n",
       "\n",
       "           Symmetric Mean absolute percentage error  Root Mean Squared Error  \\\n",
       "DirMo                                          1.82                    38.21   \n",
       "Direct                                         1.84                    38.94   \n",
       "DirRec                                         1.93                    40.81   \n",
       "Recursive                                      1.96                    42.80   \n",
       "MiMo                                           1.96                    44.53   \n",
       "\n",
       "           Mean absolute percentage error  \n",
       "DirMo                                1.81  \n",
       "Direct                               1.83  \n",
       "DirRec                               1.91  \n",
       "Recursive                            1.95  \n",
       "MiMo                                 1.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiMo</th>\n",
       "      <td>33.48</td>\n",
       "      <td>4727.58</td>\n",
       "      <td>2.11</td>\n",
       "      <td>41.19</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirMo</th>\n",
       "      <td>42.24</td>\n",
       "      <td>7956.50</td>\n",
       "      <td>2.24</td>\n",
       "      <td>50.38</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct</th>\n",
       "      <td>42.78</td>\n",
       "      <td>7831.94</td>\n",
       "      <td>2.34</td>\n",
       "      <td>50.88</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive</th>\n",
       "      <td>46.15</td>\n",
       "      <td>9236.10</td>\n",
       "      <td>2.37</td>\n",
       "      <td>54.69</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DirRec</th>\n",
       "      <td>46.51</td>\n",
       "      <td>10320.09</td>\n",
       "      <td>2.41</td>\n",
       "      <td>55.16</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean Absolute Error  Mean Squared Error  \\\n",
       "MiMo                     33.48             4727.58   \n",
       "DirMo                    42.24             7956.50   \n",
       "Direct                   42.78             7831.94   \n",
       "Recursive                46.15             9236.10   \n",
       "DirRec                   46.51            10320.09   \n",
       "\n",
       "           Symmetric Mean absolute percentage error  Root Mean Squared Error  \\\n",
       "MiMo                                           2.11                    41.19   \n",
       "DirMo                                          2.24                    50.38   \n",
       "Direct                                         2.34                    50.88   \n",
       "Recursive                                      2.37                    54.69   \n",
       "DirRec                                         2.41                    55.16   \n",
       "\n",
       "           Mean absolute percentage error  \n",
       "MiMo                                 2.09  \n",
       "DirMo                                2.21  \n",
       "Direct                               2.31  \n",
       "Recursive                            2.33  \n",
       "DirRec                               2.37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(exp_folder, \"exp_result.json\"), \"w\") as outfile:\n",
    "    json.dump(models_dict, outfile, skipkeys=True)\n",
    "\n",
    "for mode_name in ['val', 'test']:\n",
    "    exp_metrics = (pd.DataFrame({model_key: pd.DataFrame(models_dict[model_key][f'mean_{mode_name}_metrics']).mean(axis=1).to_dict() for model_key in models_dict.keys()}).round(2)\n",
    "                   .round(2)\n",
    "                   .sort_values(by='Mean absolute percentage error', axis=1)\n",
    "                   .transpose()\n",
    "                   )\n",
    "    exp_metrics.to_csv(os.path.join(exp_folder, f'exp_{mode_name}_metrics.csv'), mode='w', sep=';')\n",
    "    display(exp_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "5e745353-3184-4167-b027-54e5891f1e1b",
  "notebookPath": "Compare_prediction_methods.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}