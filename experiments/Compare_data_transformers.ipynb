{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xb53qjp0kkl7curr9u3lo",
    "jupyter": {
     "outputs_hidden": true
    },
    "id": "lrzqkwvWJmzC"
   },
   "outputs": [],
   "source": [
    "# Install libs\n",
    "!pip install ts-rnn yfinance sktime pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "67b0l9sh4nxemk836hxcbd",
    "id": "DjHnLRRkJmzD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 20:52:26.458086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#################################           Load libs                      #############################################\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pmdarima as pm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "from ts_rnn.model import TS_RNN\n",
    "from ts_rnn.utils import metrics_eval, train_test_pred_plot, train_val_test_pred_plot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('CRITICAL')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, ConditionalDeseasonalizer\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer, LogTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "282x6m3nvnxrmsl1lp9tkm",
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "CWJOMDbDJmzE"
   },
   "source": [
    "## Config experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "p758al4aa6sneye9dz1tf",
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jYVF7Y7oJmzJ",
    "outputId": "505f12b4-0ade-4a47-981f-79476f24a6f1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'There will be 2 fits'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#Config\n",
    "hp = HyperParameters()\n",
    "rnn_arch = {\"layers\": [\n",
    "                        [\"LSTM\", {\"units\": hp.Int(name='units',\n",
    "                                                 min_value=2,\n",
    "                                                 max_value=30,\n",
    "                                                 step=10,\n",
    "                                                 default=12\n",
    "                                                ),\n",
    "                                  \"return_sequences\": False,\n",
    "                                  \"kernel_initializer\": \"glorot_uniform\",\n",
    "                                  \"activation\": hp.Choice(name='LSTM_1_activation',\n",
    "                                                          values=['relu', 'tanh', 'sigmoid', \"linear\"],\n",
    "                                                          default='relu'),\n",
    "                                  }],\n",
    "                        [\"Dropout\", {\"rate\": hp.Float(name='dropout',\n",
    "                                                      min_value=0.0,\n",
    "                                                      max_value=0.5,\n",
    "                                                      default=0.2,\n",
    "                                                      step=0.05)\n",
    "                                     }],\n",
    "                        [\"Dense\", {\"activation\": \"linear\"}]\n",
    "                    ]}\n",
    "\n",
    "my_callbacks = [callbacks.EarlyStopping(patience=10, monitor='val_loss')]\n",
    "\n",
    "CONFIG = {\n",
    "    \"TARGET\": {'TICKERS': [\n",
    "                           'YNDX.ME',\n",
    "                           'SBER.ME',\n",
    "                           'POLY.ME',\n",
    "                           'SIBN.ME',\n",
    "                           'AMZN',\n",
    "                           'AAPL',\n",
    "                           'GOOGL',\n",
    "                           'NFLX'\n",
    "                           ],\n",
    "               'MIN_DATE': '2012-01-01',\n",
    "               'MAX_DATE': '2022-01-01'},\n",
    "    \"VAL_LEN\": 7,\n",
    "    \"TEST_LEN\": 7,\n",
    "    \"CV_FOLDS\": 5,\n",
    "    \"MODEL\": {'INIT':{\n",
    "                    'rnn_arch': rnn_arch,\n",
    "                    'tuner_hp': hp,\n",
    "                    \"strategy\": \"MiMo\", # \"Direct\", \"Recursive\", \"MiMo\"\n",
    "                    \"n_lags\": 30,\n",
    "                    \"horizon\": 7,\n",
    "                    \"tuner\": \"BayesianOptimization\", # \"RandomSearch\", \"BayesianOptimization\", \"Hyperband\"\n",
    "                    \"max_trials\": 5,\n",
    "                    \"loss\": 'mae',\n",
    "                    \"optimizer\": 'adam'\n",
    "                    },\n",
    "                'FIT':{\"epochs\": 40,\n",
    "                      \"batch_size\": 14,\n",
    "                       'callbacks': my_callbacks}\n",
    "              },\n",
    "    \"OUTLAYER_TRANSFORMERS\": ['HampelFilter',\n",
    "                              None\n",
    "                              ],\n",
    "    \"BASE_TRANSFORMERS\": [\n",
    "                        'Differencer',\n",
    "                        'LogTransformer',\n",
    "                        'BoxCoxTransformer',\n",
    "                        None\n",
    "                       ],\n",
    "    \"SEASON_TRANSFORMERS\": ['Deseasonalizer',\n",
    "                            None\n",
    "                            ],\n",
    "    \"NORM_TRANSPORMERS\": [\"MinMaxScaler\",\n",
    "                          None\n",
    "                          ],\n",
    "    \"TRANSFORMERS_ARGS\": {'HampelFilter':{'window_length': 10},\n",
    "                          'MinMaxScaler': {\"feature_range\": (0, 1)},\n",
    "                          'Differencer': {'lags': [1]},\n",
    "                          'LogTransformer':{},\n",
    "                          'BoxCoxTransformer': {},\n",
    "                          'Deseasonalizer':{'sp': 364, 'model': 'multiplicative'},\n",
    "                                }\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, n_splits=CONFIG[\"CV_FOLDS\"], test_size=CONFIG[\"VAL_LEN\"]+CONFIG[\"TEST_LEN\"])\n",
    "n_fits = (CONFIG['MODEL']['INIT']['max_trials'] *\n",
    "          len(CONFIG['OUTLAYER_TRANSFORMERS']) * \n",
    "          len(CONFIG['BASE_TRANSFORMERS']) *\n",
    "          len(CONFIG['SEASON_TRANSFORMERS']) *\n",
    "          len(CONFIG['NORM_TRANSPORMERS']) *\n",
    "          CONFIG['CV_FOLDS'] *\n",
    "          len(CONFIG['TARGET']['TICKERS']))\n",
    "f\"There will be {n_fits} fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ynjg0tzrilr5xpguvbuml",
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jjdmd_2OJmzQ"
   },
   "outputs": [],
   "source": [
    "def seve_fig_from_array(array, path, fig_name):\n",
    "    plt.plot(array)\n",
    "    plt.savefig(os.path.join(path, fig_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "r7gsdlese78zxbmu1xph6g",
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lMAqu_I3JmzX",
    "outputId": "d290b035-122d-4dd2-fecc-962998003757",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 1 Complete [00h 00m 11s]\n",
      "val_loss: 0.07334155589342117\n",
      "\n",
      "Best val_loss So Far: 0.07334155589342117\n",
      "Total elapsed time: 00h 00m 11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:ts_rnn_logger:[Training] Training ended\n",
      "INFO:ts_rnn_logger:[Timing] fit takes: 11.58 sec\n",
      "INFO:ts_rnn_logger:[Prediction] Start predict by MiMo strategy\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:ts_rnn_logger:[Prediction] End predict by MiMo strategy\n",
      "INFO:ts_rnn_logger:[Timing] predict takes: 0.25 sec\n",
      "INFO:ts_rnn_logger:[Prediction] Start predict by MiMo strategy\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:ts_rnn_logger:[Prediction] End predict by MiMo strategy\n",
      "INFO:ts_rnn_logger:[Timing] predict takes: 0.07 sec\n"
     ]
    }
   ],
   "source": [
    "# Import targets\n",
    "targets_df = yf.download(CONFIG['TARGET']['TICKERS'],\n",
    "                         start=CONFIG['TARGET']['MIN_DATE'],\n",
    "                         end=CONFIG['TARGET']['MAX_DATE']\n",
    "                        )['Adj Close']\n",
    "if isinstance(targets_df, pd.Series):\n",
    "    targets_df.name = CONFIG['TARGET']['TICKERS'][0]\n",
    "    targets_df = targets_df.to_frame()\n",
    "full_ind = pd.date_range(targets_df.index.min(), targets_df.index.max())\n",
    "targets_df = targets_df.reindex(full_ind, fill_value=np.nan).interpolate()\n",
    "\n",
    "# Make new experiment folder\n",
    "if \"reports\" not in os.listdir('.'):\n",
    "    os.makedirs(\"./reports\")\n",
    "new_folder_num = str(len(os.listdir(\"./reports\")) + 1)\n",
    "exp_folder = os.path.join(\"./reports\", \"data_tr_experiment_\" + new_folder_num)\n",
    "os.mkdir(exp_folder)\n",
    "print(f\"Save experiment in {exp_folder}\")\n",
    "\n",
    "# Save config\n",
    "CONFIG_ = deepcopy(CONFIG)\n",
    "del CONFIG_['MODEL']['INIT']['tuner_hp']\n",
    "del CONFIG_['MODEL']['FIT']['callbacks']\n",
    "with open(os.path.join(exp_folder, \"exp_config.json\"), \"w\") as outfile:\n",
    "    json.dump(CONFIG_, outfile, skipkeys=True)\n",
    "\n",
    "models_dict = {}\n",
    "\n",
    "# Train RNN models\n",
    "for outlayer_transformer_name in CONFIG['OUTLAYER_TRANSFORMERS']:\n",
    "    for norm_transformer_name in CONFIG['NORM_TRANSPORMERS']:\n",
    "        for base_transformer_name in CONFIG['BASE_TRANSFORMERS']:\n",
    "            for seasonal_transformer_name in CONFIG['SEASON_TRANSFORMERS']:\n",
    "                model_name =  f\"{outlayer_transformer_name}_{seasonal_transformer_name}_{base_transformer_name}_{norm_transformer_name}\"\n",
    "                \n",
    "                print(seasonal_transformer_name)\n",
    "                if model_name in os.listdir(exp_folder):\n",
    "                    continue \n",
    "                    \n",
    "                print(f\"Model {model_name}\")\n",
    "                model_folder = os.path.join(exp_folder, model_name)\n",
    "                os.mkdir(model_folder)\n",
    "\n",
    "                for ticker_name in CONFIG['TARGET']['TICKERS']:\n",
    "                    target = targets_df[ticker_name].dropna()\n",
    "                    series_folder = os.path.join(model_folder, ticker_name.split('.')[0])\n",
    "                    os.mkdir(series_folder)\n",
    "\n",
    "                    cv_val_metrics, cv_test_metrics = [], []\n",
    "                    cv_val_predictions, cv_test_predictions = [], []\n",
    "\n",
    "                    for train_index, val_index in tscv.split(target):\n",
    "                        # divide val to val and test\n",
    "                        test_index = val_index[CONFIG[\"VAL_LEN\"]:]\n",
    "                        val_index = val_index[:CONFIG[\"VAL_LEN\"]]\n",
    "\n",
    "                        iter_folder = f\"TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}\"\n",
    "                        print(iter_folder)\n",
    "\n",
    "                        # Create folder for cv iteration\n",
    "                        iter_folder = os.path.join(series_folder, iter_folder)\n",
    "                        plots_folder = os.path.join(iter_folder, 'plots')\n",
    "                        os.mkdir(iter_folder)\n",
    "                        os.mkdir(plots_folder)\n",
    "                        plot_id = 0\n",
    "\n",
    "                        target_train, target_val, target_test = target[train_index], target[val_index], target[test_index]\n",
    "                        seve_fig_from_array(target_train, plots_folder, f'{plot_id}_target')\n",
    "                        plot_id+=1\n",
    "\n",
    "                        # Transform\n",
    "                        # Del outlayers\n",
    "                        if outlayer_transformer_name is not None:\n",
    "                            outlayer_transformer = eval(outlayer_transformer_name)(**CONFIG['TRANSFORMERS_ARGS'][outlayer_transformer_name])\n",
    "                            target_train_tr = outlayer_transformer.fit_transform(target_train).interpolate(limit_direction=\"both\")\n",
    "                            target_val_tr = target_val\n",
    "                            seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_outlayers_removed')\n",
    "                            plot_id+=1\n",
    "                        else:\n",
    "                            target_train_tr = target_train\n",
    "                            target_val_tr = target_val\n",
    "\n",
    "                        # Delete season\n",
    "                        if seasonal_transformer_name is not None:\n",
    "                            seasonal_transformer = eval(seasonal_transformer_name)(**CONFIG['TRANSFORMERS_ARGS'][seasonal_transformer_name])\n",
    "                            target_train_tr = seasonal_transformer.fit_transform(target_train_tr)\n",
    "                            target_val_tr = seasonal_transformer.transform(target_val_tr)\n",
    "                            seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_{seasonal_transformer_name}')\n",
    "                            plot_id+=1\n",
    "\n",
    "                        # Base transform\n",
    "                        if base_transformer_name is not None:\n",
    "                            base_transformer = eval(base_transformer_name)(**CONFIG['TRANSFORMERS_ARGS'][base_transformer_name])\n",
    "                            target_train_tr = base_transformer.fit_transform(target_train_tr).interpolate(limit_direction=\"both\")\n",
    "                            target_val_tr = base_transformer.transform(target_val_tr).interpolate(limit_direction=\"both\")\n",
    "                            seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_{base_transformer_name}')\n",
    "                            plot_id+=1\n",
    "\n",
    "                        # Normalize target\n",
    "                        if norm_transformer_name is not None:\n",
    "                            target_scaler = eval(norm_transformer_name)(**CONFIG['TRANSFORMERS_ARGS'][norm_transformer_name])\n",
    "                            target_train_tr = target_scaler.fit_transform(target_train_tr.values.reshape(-1, 1))\n",
    "                            target_val_tr = target_scaler.transform(target_val_tr.values.reshape(-1, 1))\n",
    "                            target_train_tr = pd.Series(target_train_tr.flatten(), index=target_train.index, name=ticker_name)\n",
    "                            target_val_tr = pd.Series(target_val_tr.flatten(), index=target_val.index, name=ticker_name)\n",
    "\n",
    "                            seve_fig_from_array(pd.Series(target_train_tr, index=target_train.index), plots_folder, f'{plot_id}_target_scaled')\n",
    "                            plot_id+=1\n",
    "                        else:\n",
    "                            target_train_tr = target_train_tr.values.reshape(-1, 1)\n",
    "                            target_val_tr = target_val_tr.values.reshape(-1, 1)\n",
    "                            target_train_tr = pd.Series(target_train_tr.flatten(), index=target_train.index, name=ticker_name)\n",
    "                            target_val_tr = pd.Series(target_val_tr.flatten(), index=target_val.index, name=ticker_name)\n",
    "\n",
    "                        model = TS_RNN(save_dir=iter_folder, **CONFIG[\"MODEL\"]['INIT'])\n",
    "                        model.logger.info(f'[Experiment] {model_name}')\n",
    "                        model.logger.info(f'[Experiment] {ticker_name}_TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}')\n",
    "\n",
    "                        model.fit(target_train=target_train_tr, target_val=target_val_tr,\n",
    "                                  **CONFIG[\"MODEL\"]['FIT'],\n",
    "                                  verbose=1)\n",
    "\n",
    "                        predicted_val = model.predict(target=target_train_tr[-model.n_lags:],\n",
    "                                                          prediction_len=CONFIG[\"VAL_LEN\"])\n",
    "                        predicted_test = model.predict(target=np.concatenate([target_train_tr, target_val_tr])[-model.n_lags:],\n",
    "                                                          prediction_len=CONFIG[\"VAL_LEN\"])\n",
    "\n",
    "                        # inverse transform\n",
    "                        if norm_transformer_name is not None:\n",
    "                            predicted_val = pd.Series(target_scaler.inverse_transform(predicted_val.reshape(-1, 1))\n",
    "                                                                      .flatten(),\n",
    "                                                         index=target_val.index)\n",
    "                            predicted_test = pd.Series(target_scaler.inverse_transform(predicted_test.reshape(-1, 1))\n",
    "                                                                      .flatten(),\n",
    "                                                         index=target_test.index)\n",
    "                        else:\n",
    "                            predicted_val = pd.Series(predicted_val, index=target_val.index)\n",
    "                            predicted_test = pd.Series(predicted_test, index=target_test.index)\n",
    "\n",
    "                        if base_transformer_name is not None:\n",
    "                            predicted_val = base_transformer.inverse_transform(predicted_val)\n",
    "                            if base_transformer_name == 'Differencer':\n",
    "                                predicted_test = target_val[-1] + predicted_test.cumsum()\n",
    "                            else:\n",
    "                                predicted_test = base_transformer.inverse_transform(predicted_test)\n",
    "\n",
    "                        if seasonal_transformer_name is not None:\n",
    "                            predicted_val = seasonal_transformer.inverse_transform(predicted_val)\n",
    "                            predicted_test = seasonal_transformer.inverse_transform(predicted_test)\n",
    "\n",
    "                        # Calculate metrics\n",
    "                        val_mertics = metrics_eval(target_val[:len(predicted_val)], predicted_val, save_dir=iter_folder, print_result=False, name=\"val_mertics\")\n",
    "                        test_mertics = metrics_eval(target_test[:len(predicted_val)], predicted_test, save_dir=iter_folder, print_result=False, name='test_mertics')\n",
    "\n",
    "                        cv_val_metrics.append(val_mertics)\n",
    "                        cv_test_metrics.append(test_mertics)\n",
    "\n",
    "                        cv_val_predictions.append(predicted_val)\n",
    "                        cv_test_predictions.append(predicted_test)\n",
    "\n",
    "                        train_val_test_pred_plot(train=target_train,\n",
    "                                                 val=target_val,\n",
    "                                                 test=target_test,\n",
    "                                                 val_pred=predicted_val,\n",
    "                                                 test_pred=predicted_test,\n",
    "                                                 save_dir=plots_folder, show=False)\n",
    "\n",
    "                    models_dict[model_name] = {} if model_name not in models_dict else models_dict[model_name]\n",
    "                    models_dict[model_name][\"mean_val_metrics\"] = {} if \"mean_val_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_val_metrics\"]\n",
    "                    models_dict[model_name][\"mean_test_metrics\"] = {} if \"mean_test_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_test_metrics\"]\n",
    "                    models_dict[model_name][\"mean_val_metrics\"][ticker_name] = dict(pd.DataFrame(cv_val_metrics).mean())\n",
    "                    models_dict[model_name][\"mean_test_metrics\"][ticker_name] = dict(pd.DataFrame(cv_test_metrics).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auto Arima training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uwi6hae05bi75vlu68x0r",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "id": "_NCq2c7kJmzZ",
    "outputId": "d8824562-f037-468c-8cc2-6cc5763b0824",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN_2739_VAL_7_TEST_7\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,0,1)(0,1,1)[12] intercept   : AIC=inf, Time=6.12 sec\n",
      " ARIMA(0,0,0)(0,1,0)[12] intercept   : AIC=35210.462, Time=0.19 sec\n",
      " ARIMA(1,0,0)(1,1,0)[12] intercept   : AIC=29088.524, Time=6.92 sec\n",
      " ARIMA(0,0,1)(0,1,1)[12] intercept   : AIC=inf, Time=4.46 sec\n",
      " ARIMA(0,0,0)(0,1,0)[12]             : AIC=35249.077, Time=0.15 sec\n",
      " ARIMA(1,0,0)(0,1,0)[12] intercept   : AIC=29818.069, Time=0.74 sec\n",
      " ARIMA(1,0,0)(2,1,0)[12] intercept   : AIC=28948.005, Time=12.21 sec\n",
      " ARIMA(1,0,0)(2,1,1)[12] intercept   : AIC=inf, Time=14.54 sec\n",
      " ARIMA(1,0,0)(1,1,1)[12] intercept   : AIC=inf, Time=6.12 sec\n",
      " ARIMA(0,0,0)(2,1,0)[12] intercept   : AIC=35184.631, Time=11.76 sec\n",
      " ARIMA(2,0,0)(2,1,0)[12] intercept   : AIC=28928.542, Time=18.54 sec\n",
      " ARIMA(2,0,0)(1,1,0)[12] intercept   : AIC=29137.114, Time=6.41 sec\n",
      " ARIMA(2,0,0)(2,1,1)[12] intercept   : AIC=inf, Time=15.90 sec\n",
      " ARIMA(2,0,0)(1,1,1)[12] intercept   : AIC=inf, Time=7.44 sec\n",
      " ARIMA(3,0,0)(2,1,0)[12] intercept   : AIC=28929.952, Time=18.15 sec\n",
      " ARIMA(2,0,1)(2,1,0)[12] intercept   : AIC=28932.854, Time=17.36 sec\n",
      " ARIMA(1,0,1)(2,1,0)[12] intercept   : AIC=28937.406, Time=14.22 sec\n",
      " ARIMA(3,0,1)(2,1,0)[12] intercept   : AIC=28923.332, Time=20.72 sec\n",
      " ARIMA(3,0,1)(1,1,0)[12] intercept   : AIC=29143.561, Time=8.94 sec\n",
      " ARIMA(3,0,1)(2,1,1)[12] intercept   : AIC=inf, Time=19.51 sec\n",
      " ARIMA(3,0,1)(1,1,1)[12] intercept   : AIC=inf, Time=8.49 sec\n",
      " ARIMA(3,0,2)(2,1,0)[12] intercept   : AIC=28913.859, Time=20.16 sec\n",
      " ARIMA(3,0,2)(1,1,0)[12] intercept   : AIC=29140.557, Time=8.81 sec\n",
      " ARIMA(3,0,2)(2,1,1)[12] intercept   : AIC=28590.190, Time=21.73 sec\n",
      " ARIMA(3,0,2)(1,1,1)[12] intercept   : AIC=inf, Time=10.46 sec\n",
      " ARIMA(3,0,2)(2,1,2)[12] intercept   : AIC=inf, Time=23.92 sec\n"
     ]
    }
   ],
   "source": [
    "# Create model_folder\n",
    "model_name =  \"Auto ARIMA\"\n",
    "model_folder = os.path.join(exp_folder, model_name)\n",
    "os.mkdir(model_folder)\n",
    "\n",
    "for ticker_name in CONFIG['TARGET']['TICKERS']:\n",
    "    target = targets_df[ticker_name].dropna()\n",
    "    series_folder = os.path.join(model_folder, ticker_name.split('.')[0])\n",
    "    os.mkdir(series_folder)\n",
    "\n",
    "    cv_val_metrics, cv_test_metrics = [], []\n",
    "    cv_val_predictions, cv_test_predictions = [], []\n",
    "\n",
    "    for train_index, val_index in tscv.split(target):\n",
    "        # divide val to val and test\n",
    "        test_index = val_index[CONFIG[\"VAL_LEN\"]:]\n",
    "        val_index = val_index[:CONFIG[\"VAL_LEN\"]]\n",
    "        iter_folder = f\"TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}\"\n",
    "        print(iter_folder)\n",
    "\n",
    "        # Create folder for cv iteration\n",
    "        iter_folder = os.path.join(series_folder, iter_folder)\n",
    "        plots_folder = os.path.join(iter_folder, 'plots')\n",
    "        os.mkdir(iter_folder)\n",
    "        os.mkdir(plots_folder)\n",
    "        plot_id = 0\n",
    "\n",
    "        target_train, target_val, target_test = target[train_index], target[val_index], target[test_index]\n",
    "        seve_fig_from_array(target_train, plots_folder, f'{plot_id}_target')\n",
    "        plot_id+=1\n",
    "\n",
    "        arima_model = pm.auto_arima(target_train,\n",
    "                                   start_p=1, start_q=1,\n",
    "                                   test='adf',\n",
    "                                   max_p=3, max_q=3, m=12,\n",
    "                                   start_P=0, seasonal=True,\n",
    "                                   d=None, D=1, trace=True,\n",
    "                                   error_action='ignore',\n",
    "                                   suppress_warnings=True,\n",
    "                                   maxiter=10,\n",
    "                                   n_jobs=-1,\n",
    "                                   stepwise=True)\n",
    "        predicted_arima = arima_model.predict(n_periods=CONFIG[\"TEST_LEN\"] * 2)\n",
    "        predicted_val = predicted_arima[:CONFIG[\"TEST_LEN\"]]\n",
    "        predicted_test = predicted_arima[CONFIG[\"TEST_LEN\"]:]\n",
    "\n",
    "        predicted_val = pd.Series(predicted_val, index=target_val.index)\n",
    "        predicted_test = pd.Series(predicted_test, index=target_test.index)\n",
    "\n",
    "        # Calculate metrics\n",
    "        val_mertics = metrics_eval(target_val[:len(predicted_val)], predicted_val, save_dir=iter_folder, print_result=False, name=\"val_mertics\")\n",
    "        test_mertics = metrics_eval(target_test[:len(predicted_val)], predicted_test, save_dir=iter_folder, print_result=False, name='test_mertics')\n",
    "\n",
    "        cv_val_metrics.append(val_mertics)\n",
    "        cv_test_metrics.append(test_mertics)\n",
    "\n",
    "        cv_val_predictions.append(predicted_val)\n",
    "        cv_test_predictions.append(predicted_test)\n",
    "\n",
    "        train_val_test_pred_plot(train=target_train,\n",
    "                                 val=target_val,\n",
    "                                 test=target_test,\n",
    "                                 val_pred=predicted_val,\n",
    "                                 test_pred=predicted_test,\n",
    "                                 save_dir=plots_folder, show=False)\n",
    "    models_dict[model_name] = {} if model_name not in models_dict else models_dict[model_name]\n",
    "    models_dict[model_name][\"mean_val_metrics\"] = {} if \"mean_val_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_val_metrics\"]\n",
    "    models_dict[model_name][\"mean_test_metrics\"] = {} if \"mean_test_metrics\" not in models_dict[model_name] else models_dict[model_name][\"mean_test_metrics\"]\n",
    "    models_dict[model_name][\"mean_val_metrics\"][ticker_name] = dict(pd.DataFrame(cv_val_metrics).mean())\n",
    "    models_dict[model_name][\"mean_test_metrics\"][ticker_name] = dict(pd.DataFrame(cv_test_metrics).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0v3elcvir28blmkz8prtd5",
    "id": "zbUlb6anJmza",
    "outputId": "edbbcb55-1268-458d-ecc5-3964351a2fa0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                                                    Mean Absolute Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...               121.36   \n",
       "\n",
       "                                                    Mean Squared Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...             20807.0   \n",
       "\n",
       "                                                    Mean absolute percentage error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                            2.48   \n",
       "\n",
       "                                                    Root Mean Squared Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                   130.94   \n",
       "\n",
       "                                                    Symmetric Mean absolute percentage error  \n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                                      2.45  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a64dc23c-3cfd-40ff-a79b-5658e4eff3b2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HampelFilter_Deseasonalizer_Differencer_MinMaxScaler</th>\n",
       "      <td>121.36</td>\n",
       "      <td>20807.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>130.94</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a64dc23c-3cfd-40ff-a79b-5658e4eff3b2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a64dc23c-3cfd-40ff-a79b-5658e4eff3b2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a64dc23c-3cfd-40ff-a79b-5658e4eff3b2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                                                    Mean Absolute Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...               169.78   \n",
       "\n",
       "                                                    Mean Squared Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...            31795.48   \n",
       "\n",
       "                                                    Mean absolute percentage error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                            3.74   \n",
       "\n",
       "                                                    Root Mean Squared Error  \\\n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                   178.31   \n",
       "\n",
       "                                                    Symmetric Mean absolute percentage error  \n",
       "HampelFilter_Deseasonalizer_Differencer_MinMaxS...                                      3.75  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-14d4e8dd-b172-4b19-9906-89592311c798\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HampelFilter_Deseasonalizer_Differencer_MinMaxScaler</th>\n",
       "      <td>169.78</td>\n",
       "      <td>31795.48</td>\n",
       "      <td>3.74</td>\n",
       "      <td>178.31</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14d4e8dd-b172-4b19-9906-89592311c798')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-14d4e8dd-b172-4b19-9906-89592311c798 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-14d4e8dd-b172-4b19-9906-89592311c798');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "with open(os.path.join(exp_folder, \"exp_result.json\"), \"w\") as outfile:\n",
    "    json.dump(models_dict, outfile, skipkeys=True)\n",
    "\n",
    "for mode_name in ['val', 'test']:\n",
    "    exp_metrics = (pd.DataFrame({model_key: pd.DataFrame(models_dict[model_key][f'mean_{mode_name}_metrics']).mean(axis=1).to_dict() for model_key in models_dict.keys()}).round(2)\n",
    "                   .round(2)\n",
    "                   .sort_values(by='Mean absolute percentage error', axis=1)\n",
    "                   .transpose()\n",
    "                   )\n",
    "    exp_metrics.to_csv(os.path.join(exp_folder, f'exp_{mode_name}_metrics.csv'), mode='w', sep=';')\n",
    "    display(exp_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "578c42be-f400-49f8-aa95-ba798d42b6bd",
  "notebookPath": "Compate_data_transformers.ipynb",
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}