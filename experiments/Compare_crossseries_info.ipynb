{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "6hfkt59u8qfihrbrhrwjg",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install libs\n",
    "!pip install ts-rnn yfinance sktime pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "mr7vspru6id1moy8sbqut6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:08:01.903158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from keras_tuner import HyperParameters\n",
    "from tensorflow.keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "\n",
    "from ts_rnn.model import TS_RNN\n",
    "from ts_rnn.feature_selection import feature_importance\n",
    "from ts_rnn.utils import metrics_eval, train_val_test_pred_plot\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer, LogTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "seqz21oto8bsn3ddxekadm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "rnn_arch = {\"layers\": [\n",
    "                        [\"LSTM\", {\"units\": hp.Int(name='units',\n",
    "                                                 min_value=2,\n",
    "                                                 max_value=40,\n",
    "                                                 step=10,\n",
    "                                                 default=12\n",
    "                                                ),\n",
    "                                  \"return_sequences\": True,\n",
    "                                  \"kernel_initializer\": \"glorot_uniform\",\n",
    "                                  \"activation\": hp.Choice(name='LSTM_1_activation',\n",
    "                                                          values=['relu', 'tanh', 'sigmoid', \"linear\"],\n",
    "                                                          default='relu'),\n",
    "                                  }],\n",
    "                        [\"Dropout\", {\"rate\": hp.Float(name='dropout',\n",
    "                                                      min_value=0.0,\n",
    "                                                      max_value=0.5,\n",
    "                                                      default=0.2,\n",
    "                                                      step=0.05)\n",
    "                                     }],\n",
    "                        [\"LSTM\", {\"units\": hp.Int(name='units',\n",
    "                                                 min_value=2,\n",
    "                                                 max_value=40,\n",
    "                                                 step=10,\n",
    "                                                 default=12\n",
    "                                                ),\n",
    "                                  \"return_sequences\": False,\n",
    "                                  \"kernel_initializer\": \"glorot_uniform\",\n",
    "                                  \"activation\": hp.Choice(name='LSTM_1_activation',\n",
    "                                                          values=['relu', 'tanh', 'sigmoid', \"linear\"],\n",
    "                                                          default='relu'),\n",
    "                                  }],\n",
    "                        [\"Dense\", {\"activation\": \"linear\"}]\n",
    "                    ]}\n",
    "\n",
    "my_callbacks = [callbacks.EarlyStopping(patience=10, monitor='val_loss')]\n",
    "\n",
    "CONFIG = {\n",
    "    \"TARGET\": {'TICKERS': [\n",
    "                           'YNDX.ME',\n",
    "                           'SBER.ME',\n",
    "                           'POLY.ME',\n",
    "                           'SIBN.ME',\n",
    "                           'AMZN',\n",
    "                           'AAPL',\n",
    "                           'GOOGL',\n",
    "                           'NFLX'\n",
    "                           ],\n",
    "               'MIN_DATE': '2012-01-01',\n",
    "               'MAX_DATE': '2022-01-01'},\n",
    "    'FACTORS': {'TICKERS': [\n",
    "                            'USDRUB=X',\n",
    "                            'EURRUB=X',\n",
    "                            'BZ=F', # Brent\n",
    "                            'GC=F', # Gold\n",
    "                            '^GSPC', # S&P 500\n",
    "                            '^IXIC', # NASDAQ\n",
    "                            '^DJI', # Dow Jones\n",
    "                            ],\n",
    "                'MIN_DATE': '2012-01-01',\n",
    "                'MAX_DATE': '2022-01-01'\n",
    "    },\n",
    "\n",
    "    \"VAL_LEN\": 7,\n",
    "    \"TEST_LEN\": 7,\n",
    "    'CV_FOLDS': 5,\n",
    "    \"MODEL\": {'INIT': {\n",
    "                    'rnn_arch': rnn_arch,\n",
    "                    'tuner_hp': hp,\n",
    "                    \"strategy\": \"MiMo\", # \"Direct\", \"Recursive\", \"MiMo\"\n",
    "                    \"n_lags\": 30,\n",
    "                    \"horizon\": 7,\n",
    "                    \"tuner\": \"BayesianOptimization\", # \"RandomSearch\", \"BayesianOptimization\", \"Hyperband\"\n",
    "                    \"max_trials\": 10,\n",
    "                    \"loss\": 'mae',\n",
    "                    \"optimizer\": 'adam'\n",
    "                    },\n",
    "                'FIT':{\"epochs\": 100,\n",
    "                      \"batch_size\": 14,\n",
    "                       'callbacks': my_callbacks}\n",
    "              },\n",
    "    \"OUTLAYER_TRANSFORMERS\": 'HampelFilter',\n",
    "    \"SEASON_TRANSFORMERS\": None,\n",
    "    \"BASE_TRANSFORMERS\": 'Differencer', # 'Differencer', 'LogTransformer', 'BoxCoxTransformer',\n",
    "    \"NORM_TRANSPORMERS\": \"MinMaxScaler\",\n",
    "    \"TRANSFORMERS_ARGS\": { 'HampelFilter':{'window_length': 10},\n",
    "                                'MinMaxScaler': {\"feature_range\": (0, 1)},\n",
    "                                'Differencer': {'lags': [1]},\n",
    "                                'LogTransformer':{},\n",
    "                                'BoxCoxTransformer': {},\n",
    "                                'Deseasonalizer':{'sp': 364,\n",
    "                                                  'model': 'multiplicative'},\n",
    "                          },\n",
    "    'FEATURE_SELECTION': {'ratio':0.3, 'metric':\"mae\", 'max_iter':100}\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, n_splits=CONFIG[\"CV_FOLDS\"], test_size=CONFIG[\"VAL_LEN\"] +CONFIG[\"TEST_LEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "wlbw2j19mmcb37z1ejh1v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seve_fig_from_array(array, path, fig_name):\n",
    "    plt.plot(array)\n",
    "    plt.savefig(os.path.join(path, fig_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0k4myoflczsc5555x1auobu",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import targets\n",
    "targets_df = yf.download(CONFIG['TARGET']['TICKERS'],\n",
    "                         start=CONFIG['TARGET']['MIN_DATE'],\n",
    "                         end=CONFIG['TARGET']['MAX_DATE']\n",
    "                        )['Adj Close']\n",
    "if isinstance(targets_df, pd.Series):\n",
    "    targets_df.name = CONFIG['TARGET']['TICKERS'][0]\n",
    "    targets_df = targets_df.to_frame()\n",
    "full_ind = pd.date_range(targets_df.index.min(), targets_df.index.max())\n",
    "targets_df = targets_df.reindex(full_ind, fill_value=np.nan).interpolate()\n",
    "\n",
    "# Import targets\n",
    "if CONFIG['FACTORS']['TICKERS'] != []:\n",
    "    factors_df = yf.download(CONFIG['FACTORS']['TICKERS'],\n",
    "                             start=CONFIG['FACTORS']['MIN_DATE'],\n",
    "                             end=CONFIG['FACTORS']['MAX_DATE'])['Adj Close']\n",
    "    if isinstance(factors_df, pd.Series):\n",
    "        factors_df.name = CONFIG['FACTORS']['TICKERS'][0]\n",
    "        factors_df = factors_df.to_frame()\n",
    "    factors_df = factors_df.reindex(full_ind, fill_value=np.nan).interpolate()\n",
    "both_index = pd.concat([targets_df, factors_df], axis=1).dropna().index\n",
    "targets_df = targets_df.loc[both_index]\n",
    "factors_df = factors_df.loc[both_index]\n",
    "\n",
    "# Make new experiment folder\n",
    "if \"reports\" not in os.listdir('.'):\n",
    "    os.makedirs(\"./reports\")\n",
    "new_folder_num = str(len(os.listdir(\"./reports\")) + 1)\n",
    "exp_folder = os.path.join(\"./reports\", \"factors_experiment_\" + new_folder_num)\n",
    "os.mkdir(exp_folder)\n",
    "print(f\"Save experiment in {exp_folder}\")\n",
    "\n",
    "# Save config\n",
    "CONFIG_ = deepcopy(CONFIG)\n",
    "del CONFIG_['MODEL']['INIT']['tuner_hp']\n",
    "del CONFIG_['MODEL']['FIT']['callbacks']\n",
    "with open(os.path.join(exp_folder, \"exp_config.json\"), \"w\") as outfile:\n",
    "    json.dump(CONFIG_, outfile, skipkeys=True)\n",
    "\n",
    "\n",
    "models_dict = {}\n",
    "\n",
    "for model_type in ['GLOBAL']: # 'LOCAL', 'GLOBAL'\n",
    "    for use_factors in [True, False]:\n",
    "        # Create model_folder\n",
    "        model_name = model_type + \"_WITH_FACTORS\" if use_factors else model_type + \"_WITHOUT_FACTORS\"\n",
    "        print(f\"Model {model_name}\")\n",
    "        model_folder = os.path.join(exp_folder, model_name)\n",
    "        os.mkdir(model_folder)\n",
    "\n",
    "        iter_list = CONFIG['TARGET']['TICKERS'] if model_type=='LOCAL' else [CONFIG['TARGET']['TICKERS']]\n",
    "\n",
    "        for ticker_name in iter_list:\n",
    "            target = targets_df[ticker_name].dropna()\n",
    "            if isinstance(target, pd.Series):\n",
    "                target = target.to_frame()\n",
    "            series_folder = os.path.join(model_folder, ticker_name.split('.')[0]) if model_type == 'LOCAL' else os.path.join(model_folder,'GLOBAL')\n",
    "            os.mkdir(series_folder)\n",
    "\n",
    "            cv_val_metrics, cv_test_metrics = [], []\n",
    "            cv_val_predictions, cv_test_predictions = [], []\n",
    "\n",
    "            for train_index, val_index in tscv.split(target):\n",
    "                start_time = time.time()\n",
    "\n",
    "                # divide val to val and test\n",
    "                test_index = val_index[CONFIG[\"VAL_LEN\"]:]\n",
    "                val_index = val_index[:CONFIG[\"VAL_LEN\"]]\n",
    "\n",
    "                iter_folder = f\"TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}\"\n",
    "\n",
    "                # Create folder for cv iteration\n",
    "                iter_folder = os.path.join(series_folder, iter_folder)\n",
    "\n",
    "                os.mkdir(iter_folder)\n",
    "\n",
    "                target_train, target_val, target_test = target.iloc[train_index], target.iloc[val_index], target.iloc[test_index]\n",
    "\n",
    "\n",
    "                target_train_tr_full = None\n",
    "                target_val_tr_full = None\n",
    "\n",
    "                processers_dict = {}\n",
    "                for target_name in target_train.columns:\n",
    "                    target_folder = os.path.join(iter_folder, target_name.split('.')[0])\n",
    "                    os.mkdir(target_folder)\n",
    "                    plots_folder = os.path.join(target_folder, 'plots')\n",
    "                    os.mkdir(plots_folder)\n",
    "                    plot_id = 0\n",
    "\n",
    "                    target_train_smpl = target_train[target_name]\n",
    "                    target_val_smpl = target_val[target_name]\n",
    "\n",
    "                    seve_fig_from_array(target_train_smpl, plots_folder, f'{plot_id}_target_{target_name.split(\".\")[0]}')\n",
    "                    plot_id += 1\n",
    "                    \n",
    "                    processers_dict[target_name] = {}\n",
    "                    if CONFIG[\"OUTLAYER_TRANSFORMERS\"] is not None:\n",
    "                        outlayer_transformer = eval(CONFIG[\"OUTLAYER_TRANSFORMERS\"])(\n",
    "                            **CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"OUTLAYER_TRANSFORMERS\"]])\n",
    "                        target_train_tr = outlayer_transformer.fit_transform(target_train_smpl).interpolate(\n",
    "                            limit_direction=\"both\")\n",
    "                        target_val_tr = target_val_smpl\n",
    "                        seve_fig_from_array(target_train_tr, plots_folder, f'{plot_id}_target_outlayers_removed_{target_name.split(\".\")[0]}')\n",
    "                        plot_id += 1\n",
    "                    else:\n",
    "                        target_train_tr = target_train_smpl\n",
    "                        target_val_tr = target_val_smpl\n",
    "\n",
    "                    if CONFIG[\"SEASON_TRANSFORMERS\"] is not None:\n",
    "                        seasonal_transformer = eval(CONFIG[\"SEASON_TRANSFORMERS\"])(\n",
    "                            **CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"SEASON_TRANSFORMERS\"]])\n",
    "                        target_train_tr = seasonal_transformer.fit_transform(target_train_tr)\n",
    "                        target_val_tr = seasonal_transformer.transform(target_val_tr)\n",
    "                        processers_dict[target_name]['SEASON_TRANSFORMERS'] = seasonal_transformer\n",
    "\n",
    "                        seve_fig_from_array(target_train_tr, plots_folder,\n",
    "                                            f'{plot_id}_target_{CONFIG[\"SEASON_TRANSFORMERS\"]}_{target_name.split(\".\")[0]}')\n",
    "                        plot_id += 1\n",
    "\n",
    "                    if CONFIG[\"BASE_TRANSFORMERS\"] is not None:\n",
    "                        base_transformer = eval(CONFIG[\"BASE_TRANSFORMERS\"])(\n",
    "                            **CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"BASE_TRANSFORMERS\"]])\n",
    "                        target_train_tr = base_transformer.fit_transform(target_train_tr).interpolate(\n",
    "                            limit_direction=\"both\")\n",
    "                        target_val_tr = base_transformer.transform(target_val_tr).interpolate(limit_direction=\"both\")\n",
    "                        processers_dict[target_name]['BASE_TRANSFORMERS'] = base_transformer\n",
    "\n",
    "                        seve_fig_from_array(target_train_tr, plots_folder,\n",
    "                                            f'{plot_id}_target_{CONFIG[\"BASE_TRANSFORMERS\"]}_{target_name.split(\".\")[0]}')\n",
    "                        plot_id += 1\n",
    "\n",
    "                    # Normalize target\n",
    "                    if CONFIG[\"NORM_TRANSPORMERS\"] is not None:\n",
    "                        target_scaler = eval(CONFIG[\"NORM_TRANSPORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"NORM_TRANSPORMERS\"]])\n",
    "                        target_train_tr = target_scaler.fit_transform(target_train_tr.values.reshape(-1, 1))\n",
    "                        target_val_tr = target_scaler.transform(target_val_tr.values.reshape(-1, 1))\n",
    "                        target_train_tr = pd.Series(target_train_tr.flatten(), index=target_train.index, name=target_name)\n",
    "                        target_val_tr = pd.Series(target_val_tr.flatten(), index=target_val.index, name=target_name)\n",
    "\n",
    "                        processers_dict[target_name]['NORM_TRANSPORMERS'] = target_scaler\n",
    "\n",
    "                        seve_fig_from_array(pd.Series(target_train_tr, index=target_train.index), plots_folder,\n",
    "                                            f'{plot_id}_target_scaled_{target_name.split(\".\")[0]}')\n",
    "                        plot_id += 1\n",
    "                    else:\n",
    "                        target_train_tr = target_train_tr\n",
    "                        target_val_tr = target_val_tr\n",
    "\n",
    "                    if target_train_tr_full is None:\n",
    "                        target_train_tr_full = target_train_tr\n",
    "                        target_val_tr_full = target_val_tr\n",
    "                    else:\n",
    "                        target_train_tr_full = pd.concat([target_train_tr_full, target_train_tr], axis=1)\n",
    "                        target_val_tr_full = pd.concat([target_val_tr_full, target_val_tr], axis=1)\n",
    "\n",
    "                if use_factors:\n",
    "                    factors_train, factors_val = factors_df.iloc[train_index], factors_df.iloc[val_index]\n",
    "                    factors_scaler = eval(CONFIG[\"NORM_TRANSPORMERS\"])(**CONFIG['TRANSFORMERS_ARGS'][CONFIG[\"NORM_TRANSPORMERS\"]])\n",
    "                    factors_train_tr = factors_scaler.fit_transform(factors_train.values)\n",
    "                    factors_val_tr = factors_scaler.transform(factors_val.values)\n",
    "                    factors_train_tr = pd.DataFrame(factors_train_tr, index=factors_train.index, columns=factors_train.columns)\n",
    "                    factors_val_tr = pd.DataFrame(factors_val_tr, index=factors_val.index, columns=factors_val.columns)\n",
    "\n",
    "\n",
    "                model = TS_RNN(save_dir=iter_folder,\n",
    "                               n_features=factors_train_tr.shape[1] if use_factors else 0,\n",
    "                               **CONFIG[\"MODEL\"]['INIT'])\n",
    "                model.logger.info(f'[Experiment] {model_name}')\n",
    "                model.logger.info(f'[Experiment] {ticker_name}_TRAIN_{len(train_index)}_VAL_{len(val_index)}_TEST_{len(test_index)}')\n",
    "\n",
    "                if isinstance(target_train_tr_full, pd.Series):\n",
    "                    target_train_tr_full = target_train_tr_full.to_frame()\n",
    "                if isinstance(target_val_tr_full, pd.Series):\n",
    "                    target_val_tr_full = target_val_tr_full.to_frame()\n",
    "\n",
    "                model.fit(target_train=target_train_tr_full,\n",
    "                          target_val=target_val_tr_full,\n",
    "                          factors_train=factors_train_tr if use_factors else None,\n",
    "                          factors_val=factors_val_tr if use_factors else None,\n",
    "                          **CONFIG[\"MODEL\"]['FIT'],\n",
    "                          verbose=1)\n",
    "\n",
    "                if use_factors:\n",
    "                    factors_imp_names = set()\n",
    "                    for target_ind, target_name in enumerate(target_train.columns):\n",
    "                        target_folder = os.path.join(iter_folder, target_name.split('.')[0])\n",
    "                        # take only important factors and retrain\n",
    "                        factors_names_i = feature_importance(target_train=target_train_tr_full.iloc[:, target_ind],\n",
    "                                                             target_val=target_val_tr_full.iloc[:, target_ind],\n",
    "                                                             factors_train=factors_train_tr if use_factors else None,\n",
    "                                                             model=model,\n",
    "                                                             save_dir=target_folder,\n",
    "                                                             **CONFIG['FEATURE_SELECTION']\n",
    "                                                               )\n",
    "                        factors_imp_names.update(factors_names_i)\n",
    "\n",
    "                    factors_train_tr = factors_train_tr[factors_imp_names]\n",
    "                    factors_val_tr = factors_val_tr[factors_imp_names]\n",
    "\n",
    "                    model = TS_RNN(save_dir=iter_folder,\n",
    "                                   n_features=factors_train_tr.shape[1] if use_factors else 0,\n",
    "                                   **CONFIG[\"MODEL\"]['INIT'])\n",
    "\n",
    "                    model.fit(target_train=target_train_tr_full,\n",
    "                          target_val=target_val_tr_full,\n",
    "                          factors_train=factors_train_tr if use_factors else None,\n",
    "                          factors_val=factors_val_tr if use_factors else None,\n",
    "                          **CONFIG[\"MODEL\"]['FIT'],\n",
    "                          verbose=1)\n",
    "                    \n",
    "                # Удаляем логи тюнера\n",
    "                shutil.rmtree(os.path.join(iter_folder, 'TS_RNN_tuner_log'))\n",
    "\n",
    "\n",
    "                for target_ind, target_name in enumerate(target_train.columns):\n",
    "\n",
    "                    target_folder = os.path.join(iter_folder, target_name.split('.')[0])\n",
    "                    plots_folder = os.path.join(target_folder, 'plots')\n",
    "\n",
    "                    predicted_val = model.predict(factors=factors_train_tr.iloc[-model.n_lags:] if use_factors else None,\n",
    "                                                  target=target_train_tr_full.iloc[-model.n_lags:, target_ind],\n",
    "                                                  prediction_len=CONFIG[\"VAL_LEN\"])\n",
    "                    predicted_test = model.predict(factors=pd.concat([factors_train_tr,\n",
    "                                                                      factors_val_tr], axis=0).iloc[-model.n_lags:] if use_factors else None,\n",
    "                                                   target=pd.concat([target_train_tr_full, target_val_tr_full], axis=0).iloc[-model.n_lags:, target_ind],\n",
    "                                                   prediction_len=CONFIG[\"TEST_LEN\"])\n",
    "\n",
    "                    # inverse transform\n",
    "                    if CONFIG[\"NORM_TRANSPORMERS\"] is not None:\n",
    "                        target_scaler = processers_dict[target_name]['NORM_TRANSPORMERS']\n",
    "                        predicted_val = pd.Series(target_scaler.inverse_transform(predicted_val.reshape(-1, 1))\n",
    "                                                  .flatten(),\n",
    "                                                  index=target_val.index)\n",
    "                        predicted_test = pd.Series(target_scaler.inverse_transform(predicted_test.reshape(-1, 1))\n",
    "                                                   .flatten(),\n",
    "                                                   index=target_test.index)\n",
    "                    else:\n",
    "                        predicted_val = pd.Series(predicted_val, index=target_val.index)\n",
    "                        predicted_test = pd.Series(predicted_test, index=target_test.index)\n",
    "\n",
    "                    if CONFIG[\"BASE_TRANSFORMERS\"] is not None:\n",
    "                        base_transformer = processers_dict[target_name]['BASE_TRANSFORMERS']\n",
    "                        predicted_val = base_transformer.inverse_transform(predicted_val)\n",
    "                        if CONFIG[\"BASE_TRANSFORMERS\"] == 'Differencer':\n",
    "                            predicted_test = target_val.iloc[-1, target_ind] + predicted_test.cumsum()\n",
    "                        else:\n",
    "                            predicted_test = base_transformer.inverse_transform(predicted_test)\n",
    "\n",
    "                    if CONFIG[\"SEASON_TRANSFORMERS\"] is not None:\n",
    "                        seasonal_transformer = processers_dict[target_name]['SEASON_TRANSFORMERS']\n",
    "                        predicted_val = seasonal_transformer.inverse_transform(predicted_val)\n",
    "                        predicted_test = seasonal_transformer.inverse_transform(predicted_test)\n",
    "                    \n",
    "                    predicted_val.name = target_name\n",
    "                    predicted_val.to_csv(os.path.join(target_folder, f'val_predictions.csv'), mode='w', sep=';')\n",
    "                    predicted_test.name = target_name\n",
    "                    predicted_test.to_csv(os.path.join(target_folder, f'test_predictions.csv'), mode='w', sep=';')\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    val_mertics = metrics_eval(target_val[:len(predicted_val)][target_name], predicted_val, save_dir=target_folder,\n",
    "                                               print_result=False, name=\"val_mertics\")\n",
    "                    test_mertics = metrics_eval(target_test[:len(predicted_val)][target_name], predicted_test, save_dir=target_folder,\n",
    "                                                print_result=False, name='test_mertics')\n",
    "\n",
    "                    cv_val_metrics.append(val_mertics)\n",
    "                    cv_test_metrics.append(test_mertics)\n",
    "\n",
    "                    cv_val_predictions.append(predicted_val)\n",
    "                    cv_test_predictions.append(predicted_test)\n",
    "\n",
    "                    train_val_test_pred_plot(train=target_train[target_name],\n",
    "                                             val=target_val[target_name],\n",
    "                                             test=target_test[target_name],\n",
    "                                             val_pred=predicted_val,\n",
    "                                             test_pred=predicted_test,\n",
    "                                             name_add=target_name,\n",
    "                                             save_dir=plots_folder, show=False)\n",
    "\n",
    "            models_dict[model_name] = {} if model_name not in models_dict else models_dict[model_name]\n",
    "            models_dict[model_name][\"mean_val_metrics\"] = {} if \"mean_val_metrics\" not in models_dict[model_name] else \\\n",
    "            models_dict[model_name][\"mean_val_metrics\"]\n",
    "            models_dict[model_name][\"mean_test_metrics\"] = {} if \"mean_test_metrics\" not in models_dict[model_name] else \\\n",
    "            models_dict[model_name][\"mean_test_metrics\"]\n",
    "#                 models_dict[model_name][\"val_predictions\"] = {} if \"val_predictions\" not in models_dict[model_name] else \\\n",
    "#                 models_dict[model_name][\"val_predictions\"]\n",
    "            models_dict[model_name][\"mean_val_metrics\"][target_name] = dict(pd.DataFrame(cv_val_metrics).mean())\n",
    "            models_dict[model_name][\"mean_test_metrics\"][target_name] = dict(pd.DataFrame(cv_test_metrics).mean())\n",
    "#                 models_dict[model_name][\"val_predictions\"][target_name] = dict(pd.DataFrame(cv_val_predictions).mean())\n",
    "\n",
    "            end_time = time.time()\n",
    "            model.logger.info(f\"[Experiment] Iteration takes: {round(end_time - start_time, 2)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cellId": "xqli61twl10vzsbrpeudsi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCAL_WITH_FACTORS</th>\n",
       "      <td>37.35</td>\n",
       "      <td>5983.80</td>\n",
       "      <td>1.92</td>\n",
       "      <td>43.69</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCAL_WITHOUT_FACTORS</th>\n",
       "      <td>36.82</td>\n",
       "      <td>6132.89</td>\n",
       "      <td>1.93</td>\n",
       "      <td>43.45</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL_WITHOUT_FACTORS</th>\n",
       "      <td>137.18</td>\n",
       "      <td>63201.30</td>\n",
       "      <td>7.35</td>\n",
       "      <td>157.46</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL_WITH_FACTORS</th>\n",
       "      <td>139.90</td>\n",
       "      <td>65764.89</td>\n",
       "      <td>7.50</td>\n",
       "      <td>160.09</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Absolute Error  Mean Squared Error  \\\n",
       "LOCAL_WITH_FACTORS                    37.35             5983.80   \n",
       "LOCAL_WITHOUT_FACTORS                 36.82             6132.89   \n",
       "GLOBAL_WITHOUT_FACTORS               137.18            63201.30   \n",
       "GLOBAL_WITH_FACTORS                  139.90            65764.89   \n",
       "\n",
       "                        Symmetric Mean absolute percentage error  \\\n",
       "LOCAL_WITH_FACTORS                                          1.92   \n",
       "LOCAL_WITHOUT_FACTORS                                       1.93   \n",
       "GLOBAL_WITHOUT_FACTORS                                      7.35   \n",
       "GLOBAL_WITH_FACTORS                                         7.50   \n",
       "\n",
       "                        Root Mean Squared Error  \\\n",
       "LOCAL_WITH_FACTORS                        43.69   \n",
       "LOCAL_WITHOUT_FACTORS                     43.45   \n",
       "GLOBAL_WITHOUT_FACTORS                   157.46   \n",
       "GLOBAL_WITH_FACTORS                      160.09   \n",
       "\n",
       "                        Mean absolute percentage error  \n",
       "LOCAL_WITH_FACTORS                                1.92  \n",
       "LOCAL_WITHOUT_FACTORS                             1.92  \n",
       "GLOBAL_WITHOUT_FACTORS                            6.91  \n",
       "GLOBAL_WITH_FACTORS                               7.04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Symmetric Mean absolute percentage error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCAL_WITH_FACTORS</th>\n",
       "      <td>30.31</td>\n",
       "      <td>3272.60</td>\n",
       "      <td>2.02</td>\n",
       "      <td>37.71</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCAL_WITHOUT_FACTORS</th>\n",
       "      <td>32.01</td>\n",
       "      <td>3947.23</td>\n",
       "      <td>2.10</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL_WITHOUT_FACTORS</th>\n",
       "      <td>150.87</td>\n",
       "      <td>75732.38</td>\n",
       "      <td>7.66</td>\n",
       "      <td>171.63</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL_WITH_FACTORS</th>\n",
       "      <td>155.39</td>\n",
       "      <td>79798.76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>176.34</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Absolute Error  Mean Squared Error  \\\n",
       "LOCAL_WITH_FACTORS                    30.31             3272.60   \n",
       "LOCAL_WITHOUT_FACTORS                 32.01             3947.23   \n",
       "GLOBAL_WITHOUT_FACTORS               150.87            75732.38   \n",
       "GLOBAL_WITH_FACTORS                  155.39            79798.76   \n",
       "\n",
       "                        Symmetric Mean absolute percentage error  \\\n",
       "LOCAL_WITH_FACTORS                                          2.02   \n",
       "LOCAL_WITHOUT_FACTORS                                       2.10   \n",
       "GLOBAL_WITHOUT_FACTORS                                      7.66   \n",
       "GLOBAL_WITH_FACTORS                                         7.94   \n",
       "\n",
       "                        Root Mean Squared Error  \\\n",
       "LOCAL_WITH_FACTORS                        37.71   \n",
       "LOCAL_WITHOUT_FACTORS                     39.95   \n",
       "GLOBAL_WITHOUT_FACTORS                   171.63   \n",
       "GLOBAL_WITH_FACTORS                      176.34   \n",
       "\n",
       "                        Mean absolute percentage error  \n",
       "LOCAL_WITH_FACTORS                                2.00  \n",
       "LOCAL_WITHOUT_FACTORS                             2.07  \n",
       "GLOBAL_WITHOUT_FACTORS                            7.21  \n",
       "GLOBAL_WITH_FACTORS                               7.46  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(exp_folder, \"exp_result.json\"), \"w\") as outfile:\n",
    "    json.dump(models_dict, outfile, skipkeys=True)\n",
    "\n",
    "for mode_name in ['val', 'test']:\n",
    "    exp_metrics = (pd.DataFrame({model_key: pd.DataFrame(models_dict[model_key][f'mean_{mode_name}_metrics']).mean(axis=1).to_dict() for model_key in models_dict.keys()}).round(2)\n",
    "                   .round(2)\n",
    "                   .sort_values(by='Mean absolute percentage error', axis=1)\n",
    "                   .transpose()\n",
    "                   )\n",
    "    exp_metrics.to_csv(os.path.join(exp_folder, f'exp_{mode_name}_metrics.csv'), mode='w', sep=';')\n",
    "    display(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ttbnxgkwbpj5kh1fv3tls7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "45b46eee-ac71-4d5e-946f-cd1cc3e77d1c",
  "notebookPath": "Compare_crossseries_info.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}